import os
import streamlit as st
import pandas as pd
import logging
from datetime import datetime
from typing import Dict, Any
import traceback 

# è¿½åŠ : CSS ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§æ³¨å…¥ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
CSS_PATH = "style_report.css"

def _inject_report_css():
    """style_report.css ãŒå­˜åœ¨ã™ã‚Œã°èª­ã¿è¾¼ã¿ã€<style> ã‚¿ã‚°ã¨ã—ã¦æŒ¿å…¥ã™ã‚‹"""
    if os.path.exists(CSS_PATH):
        try:
            with open(CSS_PATH, "r", encoding="utf-8") as f:
                css_content = f.read()
            st.markdown(f"<style>{css_content}</style>", unsafe_allow_html=True)
        except Exception as css_err:
            logging.warning(f"CSS èª­ã¿è¾¼ã¿ã«å¤±æ•—: {css_err}")
    else:
        logging.info(f"{CSS_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚CSS ã¯èª­ã¿è¾¼ã¾ã‚Œã¾ã›ã‚“ã€‚")

from langgraph.graph import StateGraph
from langchain_openai import ChatOpenAI
from langchain_community.callbacks.streamlit import StreamlitCallbackHandler
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
import code_executor
from safety_checker import SafetyChecker
from code_executor import CodeExecutor
from llm_client import LLMClient
from pandas_dataframe_agent import create_pandas_dataframe_agent

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

###############################################################################
# Context and Utility Dataclasses
###############################################################################

class ConversationContext:
    """
    ä¸€é€£ã®åˆ†æã¨ãƒãƒ£ãƒƒãƒˆã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    """
    def __init__(self):
        self.user_prompt: str | None = None
        self.refined_prompt: str | None = None
        self.plan: pd.DataFrame | None = None
        self.prepare_results: Dict[str, pd.DataFrame] | None = None
        self.visualize_results: list[Dict[str, str]] | None = None
        self.report: str | None = None
        self.chat_history: list[Dict[str, str]] = []

    def get_full_context_as_string(self) -> str:
        """
        ä¿æŒã—ã¦ã„ã‚‹ã™ã¹ã¦ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜ä¸€ã®æ–‡å­—åˆ—ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦è¿”ã™ã€‚
        """
        context_parts = []
        if self.user_prompt:
            context_parts.append(f"## ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…ƒã®ä¾é ¼å†…å®¹\n{self.user_prompt}")
        if self.refined_prompt:
            context_parts.append(f"## åˆ†ææ–¹é‡\n{self.refined_prompt}")
        if self.plan is not None and not self.plan.empty:
            context_parts.append(f"## å®Ÿè¡Œã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ãƒ—ãƒ©ãƒ³\n{self.plan.to_markdown()}")
        if self.prepare_results:
            prepared_dfs = ", ".join(self.prepare_results.keys())
            context_parts.append(f"## ã‚¿ã‚¹ã‚¯(prepare)ã§ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ä¸€è¦§\n{prepared_dfs}")
        if self.visualize_results:
            viz_tasks = "\n".join([f"- {res.get('task', 'N/A')}" for res in self.visualize_results])
            context_parts.append(f"## ã‚¿ã‚¹ã‚¯(visualize)ã®æ¦‚è¦\n{viz_tasks}")
        if self.report:
            context_parts.append(f"## ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆå…¨æ–‡\n{self.report}")

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ™‚ç³»åˆ—ã§è¿½åŠ  (æœ€æ–°ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼è³ªå•ã¯å«ã‚ãªã„)
        history_str = "\n".join([f"### {msg['role']}\n{msg['content']}" for msg in self.chat_history[:-1]])
        if history_str:
            context_parts.append(f"## ã“ã‚Œã¾ã§ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´\n{history_str}")
            
        return "\n\n---\n\n".join(context_parts)

class Plan(BaseModel):
    category: str
    task: str
    input: list[str]
    output: str | None
    output_columns: list[str] | None

class ResponseFormatter(BaseModel):
    plans: list[Plan]

class RefinePromptFormat(BaseModel):
    refined_prompt: str

###############################################################################
# Session Helpers                                                              
###############################################################################

def initialize_session_state(initial_df_dict: Dict[str, pd.DataFrame]):
    # ä¸€åº¦ã ã‘å®Ÿè¡Œã•ã‚Œã‚‹åˆæœŸåŒ–å‡¦ç†
    if "initialized" not in st.session_state:
        st.session_state.initial_df_dict = initial_df_dict
        st.session_state.safety_checker = SafetyChecker()
        st.session_state.code_executor = CodeExecutor(initial_df_dict)
        st.session_state.execution_history = []
        st.session_state.generated_codes = []
        st.session_state.generated_report = ""
        st.session_state.work_df_dict: Dict[str, pd.DataFrame] = {}
        st.session_state.initialized = True

    # ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½è¿½åŠ ã«ä¼´ã† stateã€‚å¤ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§ã‚‚ã‚¨ãƒ©ãƒ¼ã«ãªã‚‰ãªã„ã‚ˆã†ã«ã€å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦åˆæœŸåŒ–ã™ã‚‹ã€‚
    if "conversation_context" not in st.session_state:
        st.session_state.conversation_context = ConversationContext()
    if "messages" not in st.session_state:
        st.session_state.messages = []


def log_execution(prompt: str, code: str, success: bool, error: str | None = None):
    st.session_state.execution_history.append(
        {
            "timestamp": datetime.now(),
            "prompt": prompt,
            "code": code,
            "success": success,
            "error": error,
        }
    )


def get_dataframe_info(df_list: list[dict[str, pd.DataFrame]]) -> str:
    info = ""
    for df_info in df_list:
        info += f"input_name: {df_info['input_name']}\n"
        if isinstance(df_info["input_df"], pd.DataFrame):
            info += f"Shape: {df_info['input_df'].shape}\n"
            info += f"Columns: {', '.join(df_info['input_df'].columns)}\n"
            info += "Data types:\n"
            for col, dtype in df_info["input_df"].dtypes.items():
                info += f"  {col}: {dtype}\n"
        else:
            info += f"len(input_df): {len(df_info['input_df'])}\n"
    return info


def replace_df_references(code: str, df_names: list[str]) -> str:
    """æ—§ã‚³ãƒ¼ãƒ‰ã‹ã‚‰æµç”¨ã€‚st.session_state.work_df_dict å‚ç…§ã¸æ›¸ãæ›ãˆã‚‹"""
    import io, tokenize
    from tokenize import TokenInfo

    df_set = set(df_names)
    replace_map = {
        name: f"st.session_state.work_df_dict['{name}']"
        for name in df_set
        if name in st.session_state.work_df_dict
    }

    result_tokens: list[TokenInfo] = []
    sio = io.StringIO(code)

    for tok in tokenize.generate_tokens(sio.readline):
        if tok.type == tokenize.NAME and tok.string in replace_map.keys():
            tok = TokenInfo(tok.type, replace_map[tok.string], tok.start, tok.end, tok.line)
        result_tokens.append(tok)

    return tokenize.untokenize(result_tokens)

###############################################################################
# LLM é–¢é€£                                                                    
###############################################################################

def get_llm_client() -> LLMClient | None:
    api_key = st.session_state.get("api_key") 

    if not api_key:
        return None

    if (
        "llm_client" not in st.session_state
        or st.session_state.llm_client is None
        or st.session_state.llm_client.api_key != api_key
    ):
        st.session_state.llm_client = LLMClient(api_key)

    return st.session_state.llm_client

###############################################################################
# Prompt Refinement ãƒãƒ¼ãƒ‰                                                      
###############################################################################

def refine_prompt_node(state: Dict[str, Any]):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›(ä¾é ¼å†…å®¹)ã‚’LLMã§è©³ç´°åŒ–ã—ã€å¾Œç¶šãƒãƒ¼ãƒ‰ãŒåˆ©ç”¨ã§ãã‚‹ã‚ˆã†
    state["refined_prompt"] ã¨ã—ã¦æ ¼ç´ã™ã‚‹ã€‚
    API Key ãŒæœªè¨­å®šã®å ´åˆã¯è©³ç´°åŒ–ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€å…ƒã®å…¥åŠ›ã‚’ãã®ã¾ã¾æ¸¡ã™ã€‚
    """
    user_prompt: str = state["user_prompt"]

    llm_client = get_llm_client()
    # API Key ãŒç„¡ã„å ´åˆã¯è©³ç´°åŒ–ã›ãšã«ã‚¹ã‚­ãƒƒãƒ—
    if llm_client is None:
        state["refined_prompt"] = user_prompt
        return state

    with st.spinner("ä¾é ¼å†…å®¹ã‚’è©³ç´°åŒ–ã—ã¦ã„ã¾ã™"):
        refine_prompt_text = f"""
ã‚ãªãŸã¯å„ªç§€ãªãƒˆãƒ¬ã‚¸ãƒ£ãƒªãƒ¼ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®ä¾é ¼å†…å®¹ã‚’ã‚ˆãç†è§£ã—ã€èƒŒæ™¯ã‚„æ„å›³ã‚’è¸ã¾ãˆã¦å›ç­”ã®ãŸã‚ã®åˆ†ææ–¹é‡ã‚’è©³ç´°åŒ–ã—ã¦ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
# ä¾é ¼å†…å®¹
{user_prompt}

# å‰æ
- ã‚ãªãŸã¯å£åº§æ®‹é«˜ã€å–å¼•å±¥æ­´ã€äºˆç®—ã€ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã€è²·æ›é‡‘ã€å£²æ›é‡‘ã€å€Ÿå…¥é‡‘ã€æŠ•è³‡ã€ãƒ‡ãƒªãƒãƒ†ã‚£ãƒ–ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚
- ã“ã‚Œã‚‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥ã—ã¦ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã‚„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆãŒã§ãã¾ã™ã€‚
- ä¾é ¼å†…å®¹ã‚’ãŸã å¯¾å¿œã™ã‚‹ã ã‘ã§ãªãã€èƒŒæ™¯ã®ãƒ‹ãƒ¼ã‚ºã«ç­”ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«å›ç­”æ–¹é‡ã‚’ç«‹ã¦ã¦ãã ã•ã„ã€‚

# å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ(å‰å¾Œã®èª¬æ˜ãªã©ã¯ä¸è¦ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚)
- è©³ç´°åŒ–ã—ãŸä¾é ¼å†…å®¹
- åˆ†æã®å…·ä½“çš„æ‰‹æ³•
- å¯è¦–åŒ–ã®ã‚¢ã‚¤ãƒ‡ã‚¢
- åˆ†æçµæœã§è¨˜è¿°ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆ
- åˆ†æã«ã‚ãŸã‚Šè€ƒæ…®ã™ã¹ãæ³¨æ„ç‚¹
"""
        refine_llm = ChatOpenAI(
            model="gpt-4.1",
            api_key=llm_client.api_key,
            verbose=True,
        ).with_structured_output(RefinePromptFormat)
        response = refine_llm.invoke(refine_prompt_text)
        refined_prompt = response.refined_prompt

    # è©³ç´°åŒ–çµæœã‚’ç”»é¢ã«è¡¨ç¤º
    st.markdown("<h3 class='section-header'>åˆ†ææ–¹é‡</h3>", unsafe_allow_html=True)
    state["refined_prompt"] = refined_prompt
    st.session_state.refined_prompt = refined_prompt
    
    with st.expander("åˆ†ææ–¹é‡"):
        st.markdown(st.session_state.refined_prompt, unsafe_allow_html=True)

    return state

###############################################################################
# Plan ç”Ÿæˆãƒãƒ¼ãƒ‰                                                              
###############################################################################

def generate_plan_node(state: Dict[str, Any]):
    st.markdown('<h3 class="section-header">ã‚¿ã‚¹ã‚¯ä¸€è¦§</h3>', unsafe_allow_html=True)
    # refine ãƒãƒ¼ãƒ‰ã§è©³ç´°åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚Œã°ãã¡ã‚‰ã‚’å„ªå…ˆ
    if "refined_prompt" in st.session_state:
        user_prompt: str = st.session_state.refined_prompt
    else:
        st.warning("è©³ç´°åŒ–ã•ã‚ŒãŸä¾é ¼å†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        user_prompt: str = st.session_state.user_prompt
    df_overview: str = state["df_overview"]

    with st.spinner("ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆä¸­"):
        plan_prompt_text = f"""
    ã‚ãªãŸã¯çµŒå–¶è€…ã®æ„æ€æ±ºå®šã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹å„ªç§€ãªãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚           
    ä»¥ä¸‹ã®ä¾é ¼å†…å®¹ã®æ„å›³ã‚’ã‚ˆãè€ƒãˆã€ä¾é ¼å†…å®¹ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®å…·ä½“çš„ãªã‚¹ãƒ†ãƒƒãƒ—ã«ç´°åˆ†åŒ–ã—ã¦ãã ã•ã„ã€‚
    # ä¾é ¼å†…å®¹
    {user_prompt}

    # ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦
    {df_overview}

    # æ‰‹é †
    1. ä¾é ¼å†…å®¹ã‚’ç†è§£ã™ã‚‹ã€‚èƒŒæ™¯ã«ã‚ã‚‹ãƒ‹ãƒ¼ã‚ºã‚‚å«ã‚ã¦ç†è§£ã™ã‚‹ã€‚
    2. ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’ç¢ºèªã™ã‚‹
    3. ä¾é ¼å†…å®¹ã«å›ç­”ã™ã‚‹ãŸã‚ã«ã©ã®ã‚ˆã†ãªåˆ†æã‚„ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã‚’è¡Œã†ã‹æ¤œè¨ã™ã‚‹ã€‚ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã¯å¿…è¦æœ€å°é™ã®ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãŒæœ›ã¾ã—ãã€ãƒ•ã‚£ãƒ«ã‚¿ã‚„ã—ãã„å€¤è¨­å®šãŒã§ãã‚‹ã‚ˆã†ã«ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªæ“ä½œãŒã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
    4. ä¾é ¼å†…å®¹ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«prepare(è¤‡æ•°å¯)ã€visualize(è¤‡æ•°å¯)ã€report(1ã¤ã®ã¿)ã®3ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¿ã‚¹ã‚¯ã«ç´°åˆ†åŒ–ã™ã‚‹
    5. ç´°åˆ†åŒ–ã•ã‚ŒãŸå„ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦ä»¥ä¸‹ã®å†…å®¹ã‚’å›ç­”ã™ã‚‹
        - category(prepare/visualize/report)
        - task(ä¸ãˆã‚‰ã‚ŒãŸdfã‚’ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã«ã©ã®ã‚ˆã†ãªåŠ å·¥ã¾ãŸã¯åˆ†æã‚’ã™ã‚‹ã‹å…·ä½“çš„ã‹ã¤è©³ç´°ã«æ˜è¨˜)
        - input(è¤‡æ•°ã‚ã‚‹å ´åˆã¯ãƒªã‚¹ãƒˆ)
        - output(df_ã‹ã‚‰å§‹ã¾ã‚‹å˜ä¸€ã®dataframeåâ€»visualizeã¨reportã®å ´åˆã¯ã‚¹ãƒšãƒ¼ã‚¹)
        - output_columns(å‡ºåŠ›ã™ã‚‹ã‚«ãƒ©ãƒ ã®ãƒªã‚¹ãƒˆâ€»å¯èƒ½ãªé™ã‚Šinputã®ã‚«ãƒ©ãƒ ã‚’æ®‹ã™â€»å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒã‚ã‚‹å ´åˆã®ã¿)
    6. prepareã®ã‚¿ã‚¹ã‚¯ã¯ã€visualizeã¨reportã®ã‚¿ã‚¹ã‚¯ã«å¿…è¦ãªå„dataframeã”ã¨ã«ç´°åˆ†åŒ–ã—ã¦ãã ã•ã„ã€‚(1ã‚¿ã‚¹ã‚¯1ã¤ã®dataframeã‚’outputã¨ã—ã¦æŒã¤)
    7. prepareã®ã‚¿ã‚¹ã‚¯ã¯ã€å„dataframeã‚’ã‚¤ãƒ³ãƒ—ãƒƒãƒˆã«pythonã§å®Ÿæ–½ã§ãã‚‹åˆ†æå†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚
        """

        plan_prompt = PromptTemplate.from_template("{input}")
        plan_llm = ChatOpenAI(
            model="gpt-4.1",
            temperature=0,
            api_key=get_llm_client().api_key,
            verbose=True,
        ).with_structured_output(ResponseFormatter)

        plan_chain = plan_prompt | plan_llm
        response_plan = plan_chain.invoke({"input": plan_prompt_text})
        if isinstance(response_plan, ResponseFormatter):
            plans = response_plan.plans
        else:
            plans = response_plan

        plan_df = pd.DataFrame([p.model_dump() if isinstance(p, Plan) else p for p in plans])
        plan_df["status"] = "â¬œ"
        plan_df = plan_df.reindex(
            columns=["category", "status", "task", "input", "output", "output_columns"]
        )

        st.session_state.plan = plan_df

    # ---------------- è¡¨ç¤ºãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ ----------------
    st.session_state.plan_placeholder = st.empty()
    st.session_state.plan_placeholder.dataframe(plan_df, use_container_width=True)
    
    # state æ›´æ–°
    state["plan_df"] = plan_df
    return state

###############################################################################
# Prepare ãƒãƒ¼ãƒ‰                                                               
###############################################################################

def prepare_node(state: Dict[str, Any]):
    plan_df: pd.DataFrame = state["plan_df"]
    prepare_tasks = plan_df[plan_df["category"] == "prepare"].to_dict(orient="records")

    st.markdown('<h3 class="section-header">ãƒ‡ãƒ¼ã‚¿</h3>', unsafe_allow_html=True)
    with st.expander("ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿", expanded=True):
        # ã¾ãšã‚¿ãƒ–ã‚’ã™ã¹ã¦æç”»ã—ã€å„ã‚¿ãƒ–å†…ã«ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç”¨æ„ã—ã¦ãŠã
        output_names = [task["output"] for task in prepare_tasks]
        tabs = st.tabs(output_names)

        # ã‚¿ãƒ–å â†’ ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ ã®å¯¾å¿œè¡¨
        tab_placeholders: Dict[str, Any] = {}
        for idx, name in enumerate(output_names):
            with tabs[idx]:
                # ã“ã“ã§ã¯ç©ºã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆã—ã¦ãŠãã€å¾Œã§ä¸­èº«ã‚’åŸ‹ã‚è¾¼ã‚€
                tab_placeholders[name] = st.empty()

        work_df_dict: Dict[str, pd.DataFrame] = {}
         
        try:
            for task in prepare_tasks:
                output_df_name = task.get("output")
                # ç¾åœ¨å‡¦ç†ä¸­ã®ã‚¿ãƒ–ã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’å–å¾—
                placeholder = tab_placeholders.get(output_df_name)
                with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­[{task['task']}]"):
                    st.session_state.plan.loc[
                        st.session_state.plan["task"] == task["task"], "status"
                    ] = "ğŸ”„"
                    st.session_state.plan_placeholder.dataframe(st.session_state.plan, use_container_width=True)

                    input_df_names = task["input"]

                    # å…¥åŠ› df ã‚’ dict åŒ–ï¼ˆå­˜åœ¨ã™ã‚‹ã‚‚ã®ã®ã¿ï¼‰
                    input_df_dict: Dict[str, pd.DataFrame] = {}
                    for name in input_df_names:
                        if name in work_df_dict:
                            input_df_dict[name] = work_df_dict[name].copy()
                        elif name in st.session_state.initial_df_dict:
                            input_df_dict[name] = st.session_state.initial_df_dict[name].copy()
                        else:
                            st.warning(f"DataFrame '{name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

                    if not input_df_dict:
                        st.error("æœ‰åŠ¹ãªå…¥åŠ› DataFrame ãŒç„¡ã„ãŸã‚ prepare ã‚¿ã‚¹ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue

                    st_callback = StreamlitCallbackHandler(parent_container = st.container(), max_thought_containers=2, expand_new_thoughts=False)
                    prepare_agent = create_pandas_dataframe_agent(
                        llm=ChatOpenAI(model="gpt-4.1", temperature=0, api_key=get_llm_client().api_key),
                        df=input_df_dict,
                        agent_type="zero-shot-react-description",
                        verbose=True,
                        allow_dangerous_code=True,
                        return_intermediate_steps=True,
                        include_df_in_result=True,
                        df_exec_instruction=True,
                        agent_executor_kwargs={"handle_parsing_errors": True},
                    )

                    prompt_for_data = f"""
                                    ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã§ã™ã€‚           
                                    ä»¥ä¸‹ã®taskã«å¾“ã£ã¦dataframeã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
                                    # task
                                    {task['task']}
                                    # input
                                    {input_df_names}
                                    # output
                                    {output_df_name}
                                    # output_columns
                                    {input_df_names}ã®ã‚«ãƒ©ãƒ (å¯èƒ½ãªé™ã‚Š) + {task['output_columns']}
                                    
                                    # æ³¨æ„ç‚¹
                                    - ã¾ãšåˆã‚ã«inputã®ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹head()ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯ã®å ´åˆã®ãã®æ—¨å›ç­”ã—ã¦å‡¦ç†ã‚’çµ‚äº†ã—ã¦ãã ã•ã„ã€‚
                                    - å¤‰æ•°ã€ä¸­é–“ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¯å°ã¾ã‚ã«head()ã‚’å®Ÿè¡Œã—ã¦æƒ³å®šé€šã‚Šä½œæˆã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚
                                    - outputã‚’ç”Ÿæˆã—ãŸã‚‰ã€ä»¥ä¸‹ã®ã‚ˆã†ã«{output_df_name}.jsonã¨ã„ã†åå‰ã§ä¿å­˜ã—ã¦ãã ã•ã„ã€‚
                                    {output_df_name}.to_json(
                                        f"tmp/{output_df_name}.json",
                                        orient="records",
                                        date_format="iso",
                                        date_unit="s",
                                        index=False,
                                        force_ascii=False,
                                    )
                                    """

                    prepare_agent.invoke({"input": prompt_for_data}, {"callbacks": [st_callback]})

                    # ç”Ÿæˆã•ã‚ŒãŸ json ã‚’èª­ã¿è¾¼ã¿
                    if os.path.exists(f"tmp/{output_df_name}.json"):
                        df_output = pd.read_json(f"tmp/{output_df_name}.json", orient="records")
                        work_df_dict[output_df_name] = df_output
                        st.session_state.plan.loc[
                            st.session_state.plan["output"] == output_df_name, "status"
                        ] = "âœ…"
                    else:
                        prepare_agent.invoke({"input": prompt_for_data}, {"callbacks": [st_callback]})

                        if os.path.exists(f"tmp/{output_df_name}.json"):
                            df_output = pd.read_json(f"tmp/{output_df_name}.json", orient="records")
                            work_df_dict[output_df_name] = df_output
                            st.session_state.plan.loc[
                                st.session_state.plan["output"] == output_df_name, "status"
                            ] = "âœ…"
                        else:
                            st.error(f"DataFrame '{output_df_name}' ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                            st.session_state.plan.loc[
                                st.session_state.plan["output"] == output_df_name, "status"
                            ] = "âŒ"
                            continue

                    # ç”Ÿæˆçµæœã‚’è©²å½“ã‚¿ãƒ–ã«æç”»
                    if placeholder is not None:
                        with placeholder.container():
                            st.info(f"ã‚¿ã‚¹ã‚¯: {task['task']}")
                            st.dataframe(df_output[:100], use_container_width=True)

        except Exception as e:
            # ä¾‹å¤–ç™ºç”Ÿæ™‚ã«ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã¦ç”»é¢ã¨ãƒ­ã‚°ã«å‡ºåŠ›
            st.exception(e)
            logger.exception("prepare ã‚¿ã‚¹ã‚¯å¤±æ•—")
            # task ã¾ãŸã¯ output åã§å®‰å…¨ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–° (ä¾‹å¤–æ™‚ã®ã¿)
            if output_df_name:
                st.session_state.plan.loc[
                    st.session_state.plan["output"] == output_df_name, "status"
                ] = "âŒ"
            else:
                st.session_state.plan.loc[
                    st.session_state.plan["task"] == task["task"], "status"
                ] = "âŒ"

    st.session_state.plan_placeholder.dataframe(st.session_state.plan, use_container_width=True)

    st.session_state.work_df_dict = work_df_dict
    state["work_df_dict"] = work_df_dict
    return state

###############################################################################
# Visualize ãƒãƒ¼ãƒ‰                                                             
###############################################################################

def visualize_node(state: Dict[str, Any]):
    plan_df: pd.DataFrame = state["plan_df"]
    visualize_tasks = plan_df[plan_df["category"] == "visualize"].to_dict(orient="records")

    def fix_code(code: str, error_message: str, task: dict[str, Any], df_info: str):
        """
        LLM ã«ã‚³ãƒ¼ãƒ‰ä¿®æ­£ã‚’ä¾é ¼ã—ã€å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã‚’é€šéã—ãŸä¿®æ­£ã‚³ãƒ¼ãƒ‰
        ã‚’è¿”ã—ã¾ã™ã€‚å®‰å…¨ã§ãªã„ã€ã‚‚ã—ãã¯ä¿®æ­£ã«å¤±æ•—ã—ãŸå ´åˆã¯ ``None`` ã‚’è¿”å´ã—ã¾ã™ã€‚
        """
        input_df_names = task["input"]

        try:
            # --- LLM ã¸ä¿®æ­£ä¾é ¼ ---
            fixed_code = st.session_state.llm_client.fix_code(
                code,
                error_message,
                task,
                df_info,
            )

            # --- å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ ---
            is_safe_fixed, safety_report_fixed = st.session_state.safety_checker.is_safe(fixed_code)
            if not is_safe_fixed:
                st.error("ä¿®æ­£å¾Œã®ã‚³ãƒ¼ãƒ‰ãŒå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã§å¤±æ•—ã—ã¾ã—ãŸ")
                with st.expander("å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯è©³ç´°(ä¿®æ­£å¾Œ)"):
                    st.json(safety_report_fixed)
                return None

            # DataFrame å‚ç…§ã‚’æ›¸ãæ›ãˆ
            fixed_code_replaced = replace_df_references(fixed_code, input_df_names)
            return fixed_code_replaced

        except Exception as e:
            st.exception(e)
            logger.exception("fix_code å¤±æ•—")
            return None

    st.markdown('<h3 class="section-header">ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«</h3>', unsafe_allow_html=True)
    with st.expander("ç”Ÿæˆã•ã‚ŒãŸãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«", expanded=True):
        vis_tabs = st.tabs([f"visual_{i+1}" for i in range(len(visualize_tasks))])

        for idx, task in enumerate(visualize_tasks):
            try:
                with vis_tabs[idx]:
                    with st.spinner(f"ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚’ç”Ÿæˆä¸­[{task['task']}]"):
                        st.session_state.plan.loc[
                            st.session_state.plan["task"] == task["task"], "status"
                        ] = "ğŸ”„"
                        st.session_state.plan_placeholder.dataframe(st.session_state.plan, use_container_width=True)

                        input_df_names = task["input"]
                        input_df_list = []
                        for name in input_df_names:
                            df_val = st.session_state.work_df_dict.get(name, st.session_state.initial_df_dict.get(name))
                            if df_val is None:
                                st.warning(f"DataFrame '{name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                                continue
                            input_df_list.append({"input_name": name, "input_df": df_val})
                        df_info = get_dataframe_info(input_df_list)

                        if not input_df_list:
                            continue

                        generated_code = get_llm_client().generate_code(task, df_info)

                        # ---------------- å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ ----------------
                        replaced_generated_code = replace_df_references(generated_code, input_df_names)
                        is_safe, _ = st.session_state.safety_checker.is_safe(replaced_generated_code)

                        code_to_run = replaced_generated_code
                        if not is_safe:
                            fixed = fix_code(replaced_generated_code, "å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸ", task, df_info)
                            if fixed is None:
                                # ä¿®æ­£å‡ºæ¥ãªã‹ã£ãŸå ´åˆã¯ã‚¿ã‚¹ã‚¯å¤±æ•—æ‰±ã„
                                st.session_state.plan.loc[
                                    st.session_state.plan["task"] == task["task"], "status"
                                ] = "âŒ"
                                st.session_state.plan_placeholder.dataframe(st.session_state.plan, use_container_width=True)
                                continue
                            code_to_run = fixed

                    # ---------------- ã‚³ãƒ¼ãƒ‰å®Ÿè¡Œ ----------------
                    with vis_tabs[idx]:
                        st.info(f"ã‚¿ã‚¹ã‚¯: {task['task']}")
                        # 1å›ç›®ã¨2å›ç›®ã®æç”»ãŒé‡è¤‡ã—ãªã„ã‚ˆã†ã«ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ç”¨æ„
                        output_placeholder = st.empty()

                        def run_and_render(code: str, suffix: str = "") -> tuple[bool, str | None, str | None]:
                            """ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã«æç”»ã™ã‚‹å…±é€šé–¢æ•°"""
                            # æ—¢å­˜ã®æç”»ã‚’ã‚¯ãƒªã‚¢
                            output_placeholder.empty()
                            with output_placeholder.container():
                                success_inner, stdout_inner, err_inner = (
                                    st.session_state.code_executor.execute_code(code)
                                )

                                # ãƒ­ã‚°å‡ºåŠ›
                                if stdout_inner:
                                    with st.expander(f"log{suffix}"):
                                        st.text(stdout_inner)

                                # å®Ÿè¡Œã—ãŸã‚³ãƒ¼ãƒ‰è¡¨ç¤º
                                with st.expander(f"code{suffix}"):
                                    st.code(code, language="python")

                            return success_inner, stdout_inner, err_inner

                        # 1 å›ç›®ã®å®Ÿè¡Œ
                        success, stdout, err = run_and_render(code_to_run)

                        # å®Ÿè¡Œå¤±æ•—æ™‚ã®è‡ªå‹•ä¿®æ­£
                        if not success and err:
                            fixed = fix_code(code_to_run, err, task, df_info)
                            if fixed:
                                # 2 å›ç›®ã®å®Ÿè¡Œï¼ˆä¿®æ­£å¾Œï¼‰
                                success, stdout, err = run_and_render(fixed, "(ä¿®æ­£å¾Œ)")
                                code_to_run = fixed  # æˆåŠŸã™ã‚Œã° code ã‚’æ›´æ–°

                        # 2 å›ç›®ã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
                        if not success and err:
                            st.error(err)

                    # æˆå¦ã«å¿œã˜ã¦ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜
                    st.session_state.generated_codes.append(
                        {"task": task["task"], "code": code_to_run}
                    )

                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
                    st.session_state.plan.loc[
                        st.session_state.plan["task"] == task["task"], "status"
                    ] = "âœ…" if success else "âŒ"
            except Exception as e:
                st.error(f"visualize å®Ÿè¡Œå¤±æ•—: {e}")
                st.session_state.plan.loc[
                    st.session_state.plan["task"] == task["task"], "status"
                ] = "âŒ"
    
            st.session_state.plan_placeholder.dataframe(st.session_state.plan, use_container_width=True)

    state["generated_codes"] = st.session_state.generated_codes
    return state

###############################################################################
# Report ãƒãƒ¼ãƒ‰                                                                
###############################################################################

def report_node(state: Dict[str, Any]):
    st.session_state.generated_report = []
    plan_df: pd.DataFrame = state["plan_df"]
    report_tasks = plan_df[plan_df["category"] == "report"].to_dict(orient="records")

    llm = get_llm_client()
    if not llm:
        st.error("API Key æœªè¨­å®šã®ãŸã‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return state

    for task in report_tasks:
        # prepare ã‚¿ã‚¹ã‚¯ã®æ¦‚è¦ã‚’æ–‡å­—åˆ—åŒ–
        prepare_plan = plan_df[plan_df["category"] == "prepare"][["task", "input", "output"]].to_dict(orient="records")

        input_df_names = task["input"]
        # å…¥åŠ› DataFrame ã‚’ dict å½¢å¼ {name: df} ã«å¤‰æ›
        input_df_dict = {name: st.session_state.work_df_dict[name] for name in input_df_names if name in st.session_state.work_df_dict}
        for name in input_df_names:
            if name in st.session_state.initial_df_dict:
                input_df_dict[name] = st.session_state.initial_df_dict[name]

        prompt_for_report = f"""
ã‚ãªãŸã¯è²¡å‹™åˆ†æã®çµŒé¨“è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®inputã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚‚ã¨ã«ã€taskã«å¾“ã£ã¦åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ä¾é ¼å†…å®¹
{st.session_state.user_prompt}

# ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯
{task['task']}

# ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã®èƒŒæ™¯
{st.session_state.refined_prompt}

# ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯ã®input
{input_df_names}

# ã“ã“ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™ã®çµŒç·¯
{prepare_plan}

# ã‚ãªãŸã®ã‚¿ã‚¹ã‚¯
inputã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚ˆãå‚ç…§ã—ã€taskã®èƒŒæ™¯ã‚’è¸ã¾ãˆãŸä¸Šã§å…·ä½“çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

# æ³¨æ„ç‚¹
- ã¾ãšåˆã‚ã«inputã®ãƒ‡ãƒ¼ã‚¿ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã‹head()ãªã©ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯ã®å ´åˆã®ãã®æ—¨å›ç­”ã—ã¦å‡¦ç†ã‚’çµ‚äº†ã—ã¦ãã ã•ã„ã€‚
- æ¨æ¸¬ã§å›ç­”ã›ãšã€PythonAstREPLToolã‚’ä½¿ç”¨ã—ã¦inputã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦åˆ†æã‚’è¡Œã„ã€ç¢ºèªã—ã¦ç¤ºå”†ã«å¯Œã‚“ã è¦³ç‚¹ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
- å…·ä½“çš„ãªæ•°å€¤ãªã©å®šé‡çš„ãªãƒ‡ãƒ¼ã‚¿ã‚‚æ ¹æ‹ ã«çµè«–ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
- ãƒ¬ãƒãƒ¼ãƒˆã¯markdownå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚
- ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å¿…ãš `<div data-card>` ã¨ `</div>` ã§å›²ã¿ã€ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¦–è¦šçš„ã«åŒºåˆ‡ã£ã¦ãã ã•ã„ã€‚
- å¼·èª¿ã¾ãŸã¯è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«ã¯ `<p data-alert="ok|warn|info"> ... </p>` ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
- ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã€åˆ†ææ–¹æ³•ã€åˆ†æçµæœã€ç™ºè¦‹äº‹é …ã€åˆ†æã§ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
"""
        st.markdown('<h3 class="section-header">ãƒ¬ãƒãƒ¼ãƒˆ</h3>', unsafe_allow_html=True)
        
        report_agent = create_pandas_dataframe_agent(
            llm=ChatOpenAI(model="gpt-4.1", api_key=llm.api_key),
            df=input_df_dict,
            agent_type="tool-calling",
            verbose=True,
            allow_dangerous_code=True,
            return_intermediate_steps=True,
            df_exec_instruction=False,
            agent_executor_kwargs={"handle_parsing_errors": True},
            )
        with st.spinner(f"ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­[{task['task']}]"):
            st_callback = StreamlitCallbackHandler(parent_container = st.container(), max_thought_containers=2, expand_new_thoughts=False)
            res = report_agent.invoke({"input": prompt_for_report}, {"callbacks": [st_callback]})
            st.session_state.generated_report.append(res["output"])
            #st.markdown(res["output"]) # codeãƒ–ãƒ­ãƒƒã‚¯ã§ã¯ãªãMarkdownã§è¡¨ç¤º
            with st.expander("ãƒ¬ãƒãƒ¼ãƒˆ"):
                st.markdown(res["output"], unsafe_allow_html=True)

        st.session_state.plan.loc[
            st.session_state.plan["task"] == task["task"], "status"
        ] = "âœ…"
        st.session_state.plan_placeholder.dataframe(st.session_state.plan, use_container_width=True)

    state["generated_report"] = st.session_state.generated_report
    return state

###############################################################################
# Flow Builder                                                                 
###############################################################################

def build_flow():
    g = StateGraph(dict)

    # æ–°è¦ãƒãƒ¼ãƒ‰
    g.add_node("refine", refine_prompt_node)
    g.add_node("plan", generate_plan_node)
    g.add_node("prepare", prepare_node)
    g.add_node("visualize", visualize_node)
    g.add_node("report", report_node)

    # ãƒ•ãƒ­ãƒ¼ã®æ¥ç¶š
    g.add_edge("refine", "plan")
    g.add_edge("plan", "prepare")
    g.add_edge("prepare", "visualize")
    g.add_edge("visualize", "report")
    
    # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã¨çµ‚äº†ãƒã‚¤ãƒ³ãƒˆ
    g.set_entry_point("refine")
    g.set_finish_point("report")
    compiled = g.compile()
    return compiled

###############################################################################
# Streamlit Main                                                               
###############################################################################

def main(initial_df_dict: Dict[str, pd.DataFrame]):
    st.set_page_config(page_title="Streamlit Agent (LangGraph)", layout="wide")
    # --- è¿½åŠ : CSS ã‚’æ³¨å…¥ ---
    _inject_report_css()
    initialize_session_state(initial_df_dict)

    user_prompt = st.text_area("ä¾é ¼å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=100)
    run_button = st.button("å®Ÿè¡Œ", type="primary")

    if run_button:
        if not user_prompt.strip():
            st.warning("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()

        # å®Ÿè¡Œã®ãŸã³ã«ã€å‰ã®å®Ÿè¡Œçµæœã¨ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹
        st.session_state.messages = []
        st.session_state.plan = pd.DataFrame()
        st.session_state.work_df_dict = {}
        st.session_state.generated_codes = []
        st.session_state.generated_report = ""
        st.session_state.refined_prompt = ""
        st.session_state.conversation_context = ConversationContext()
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ä¸Šæ›¸ã
        st.session_state.user_prompt = user_prompt

        llm_client = get_llm_client()
        if llm_client is None:
            st.error("API Key ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()

        df_overview = get_dataframe_info(
            [
                {"input_name": n, "input_df": df}
                for n, df in st.session_state.initial_df_dict.items()
            ]
        )

        # ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œã‚’å®‰å…¨ã«ãƒ©ãƒƒãƒ—
        try:
            flow = build_flow()
            state = {
                "user_prompt": user_prompt,
                "df_overview": df_overview,
            }
            flow.invoke(state)

            # --- å…¨ãƒ•ãƒ­ãƒ¼å®Œäº†å¾Œã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–° ---
            context = st.session_state.conversation_context
            context.user_prompt = st.session_state.user_prompt
            context.refined_prompt = st.session_state.get("refined_prompt")
            context.plan = st.session_state.get("plan")
            context.prepare_results = st.session_state.get("work_df_dict")
            context.visualize_results = st.session_state.get("generated_codes")
            context.report = "\n".join(st.session_state.get("generated_report", []))

        except Exception as e:
            # ãƒ•ãƒ­ãƒ¼å…¨ä½“ã§äºˆæœŸã›ã¬ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆã§ã‚‚ç”»é¢ãŒç™½ããªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
            st.exception(e)
            logger.exception("flow.invoke å¤±æ•—")

        st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ------------------------------------------------------------------
    # ãƒšãƒ¼ã‚¸è¡¨ç¤º/å†æç”» (ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«åŸºã¥ã„ã¦UIã‚’æ§‹ç¯‰)
    # ------------------------------------------------------------------

    # --- åˆ†æçµæœã®è¡¨ç¤º ---
    if not run_button and "plan" in st.session_state and isinstance(st.session_state.plan, pd.DataFrame) and not st.session_state.plan.empty:
        if st.session_state.get("refined_prompt"):
            st.markdown("<h3 class='section-header'>åˆ†ææ–¹é‡</h3>", unsafe_allow_html=True)
            with st.expander("åˆ†ææ–¹é‡", expanded=False):
                st.markdown(st.session_state.refined_prompt, unsafe_allow_html=True)

        st.markdown('<h3 class="section-header">ã‚¿ã‚¹ã‚¯ä¸€è¦§</h3>', unsafe_allow_html=True)
        st.dataframe(st.session_state.plan, use_container_width=True)

        # ç”Ÿæˆãƒ‡ãƒ¼ã‚¿
        if st.session_state.get("work_df_dict"):
            st.markdown('<h3 class="section-header">ãƒ‡ãƒ¼ã‚¿</h3>', unsafe_allow_html=True)
            with st.expander("ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿"):
                tabs = st.tabs(list(st.session_state.work_df_dict.keys()))
                for idx, (df_name, df_val) in enumerate(st.session_state.work_df_dict.items()):
                    with tabs[idx]:
                        # plan ã‹ã‚‰è©²å½“ã‚¿ã‚¹ã‚¯ã‚’æ¤œç´¢
                        task_info = st.session_state.plan[st.session_state.plan["output"] == df_name]
                        if not task_info.empty:
                            st.info(f"ã‚¿ã‚¹ã‚¯: {task_info.iloc[0]['task']}")
                        st.dataframe(df_val[:100], use_container_width=True, )

        # ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«å†æç”»
        if st.session_state.get("generated_codes"):
            st.markdown('<h3 class="section-header">ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«</h3>', unsafe_allow_html=True)
            with st.expander("ç”Ÿæˆã•ã‚ŒãŸãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«"):
                vis_tabs = st.tabs([f"visual_{i+1}" for i in range(len(st.session_state.generated_codes))])
                for idx, gen_code_info in enumerate(st.session_state.generated_codes):
                    with vis_tabs[idx]:
                        try:
                            task_description = gen_code_info.get("task", "ã‚¿ã‚¹ã‚¯ã®èª¬æ˜ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                            gen_code = gen_code_info.get("code", "")
                            st.info(f"ã‚¿ã‚¹ã‚¯: {task_description}")

                            success, stdout, err = st.session_state.code_executor.execute_code(gen_code)
                            if not success and err:
                                st.error(err)
                            if stdout:
                                with st.expander("log"):
                                    st.text(stdout)
                            with st.expander("code"):
                                st.code(gen_code, language="python")

                        except Exception as e:
                            st.error(f"å†æç”»å¤±æ•—: {e}")

        # ãƒ¬ãƒãƒ¼ãƒˆ
        if st.session_state.get("generated_report"):
            st.markdown('<h3 class="section-header">ãƒ¬ãƒãƒ¼ãƒˆ</h3>', unsafe_allow_html=True)
            for report in st.session_state.generated_report:
                #st.markdown(report)
                with st.expander("ãƒ¬ãƒãƒ¼ãƒˆ"):
                    st.markdown(report, unsafe_allow_html=True)

    # --- ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ã®è¡¨ç¤ºã¨å‡¦ç† ---
    # ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚ŒãŸå¾Œã®ã¿ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–
    is_report_ready = bool(
        st.session_state.get("conversation_context") and st.session_state.conversation_context.report
    )

    # --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
    if is_report_ready:
        st.divider()
        st.markdown('<h3 class="section-header">ãƒãƒ£ãƒƒãƒˆ</h3>', unsafe_allow_html=True)
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’ç”Ÿæˆãƒ»è¡¨ç¤º
    # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ã‚‚ã®ã§ã‚ã‚Œã°ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒå¿œç­”ã™ã‚‹
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                st.session_state.conversation_context.chat_history = st.session_state.messages
                full_context_str = st.session_state.conversation_context.get_full_context_as_string()
                
                last_user_prompt = st.session_state.messages[-1]["content"]

                prompt_for_chat = f"""
ã‚ãªãŸã¯ã€ã™ã§ã«è¡Œã‚ã‚ŒãŸä¸€é€£ã®åˆ†æçµæœã‚’å®Œå…¨ã«ç†è§£ã—ãŸä¸Šã§ã€è¿½åŠ ã®è³ªå•ã«ç­”ãˆã‚‹ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’è¸ã¾ãˆã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æœ€å¾Œã®è³ªå•ã«ã€è©³ç´°ã‹ã¤çš„ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
å¿…è¦ã§ã‚ã‚Œã°ã€åˆ©ç”¨å¯èƒ½ãªDataFrameã‚’åˆ†æã—ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
{full_context_str}

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æœ€å¾Œã®è³ªå•
{last_user_prompt}

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®æ„å›³ã‚’æ¨æ¸¬ã—ã¦ã€åˆ†æã®éç¨‹ã§ç”Ÿæˆã•ã‚ŒãŸDataFrameã‚’ã—ã£ã‹ã‚Šã¨ç¢ºèªã—ãŸã†ãˆã§è«–ç†çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚**

"""
                all_dfs = {**st.session_state.initial_df_dict, **st.session_state.work_df_dict}
                chat_agent = create_pandas_dataframe_agent(
                    llm=ChatOpenAI(model="gpt-4.1", temperature=0, api_key=get_llm_client().api_key),
                    df=all_dfs,
                    agent_type="zero-shot-react-description",
                    verbose=True,
                    allow_dangerous_code=True,
                    return_intermediate_steps=True,
                    agent_executor_kwargs={"handle_parsing_errors": True},
                    df_exec_instruction=True,
                )

                # StreamlitCallbackHandlerç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’ç”¨æ„
                st_callback_container = st.container()
                st_callback = StreamlitCallbackHandler(parent_container = st_callback_container, max_thought_containers=2, expand_new_thoughts=False)
                
                try:
                    # stream() ã¯ generator ã‚’è¿”ã™ãŸã‚ã€ãã®ã¾ã¾ã§ã¯ dict ã‚¢ã‚¯ã‚»ã‚¹ã§ããšä¾‹å¤–ã¨ãªã‚‹ã€‚
                    # ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ã§ä¸€æ‹¬å¿œç­”ã‚’å¾—ã‚‹å ´åˆã¯ invoke() ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
                    response_dict = chat_agent.invoke(
                        {"input": prompt_for_chat},
                        {"callbacks": [st_callback]}
                    )
                    response_text = response_dict.get("output", "")
                except Exception as e:
                    response_text = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                    logger.error(f"Chat agent invocation failed: {e}")
                
                # æœ€çµ‚çš„ãªå›ç­”ã‚’è¡¨ç¤º
                st.markdown(response_text, unsafe_allow_html=True)
                # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({"role": "assistant", "content": response_text})

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹
    if is_report_ready:
        if chat_prompt := st.chat_input(
            "ãƒ¬ãƒãƒ¼ãƒˆã‚„åˆ†æã«ã¤ã„ã¦è¿½åŠ ã§è³ªå•ã—ã¦ãã ã•ã„", disabled=not is_report_ready
        ):
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append({"role": "user", "content": chat_prompt})
            # ç”»é¢ã‚’å†å®Ÿè¡Œã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å³æ™‚è¡¨ç¤º
            st.rerun()
